{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1\n",
      "there are  13  chunks\n",
      "there are  1024  elements in ctxt_embed\n",
      "there are  12  elements in search_embed\n",
      "the context we are giving is:  全国联保 七天无理由退货 官方正品保障 全场包邮 售后无忧 扫一扫查看 企业会员购 扫一扫咨询 商家入驻 扫一扫查看 附近门店 扫一扫关注、查看 美的智慧家小程序 扫一扫关注、查看 美的智慧家公众号 扫一扫关注、查看 美的智慧家视频号 在安全设计上，美的电热水器配备了与海尔相类似的“防电墙”，能有效避免强电流流经人体。当然，防电墙只是众多防护手段之一，美的还拥有“出水断电”、“干烧漏电自动断电”等专利，以及与A.O.史密斯相同的PS安全系统，这些防护设计的思路都属于切断电源类，从源头上断绝了触电的可能。需要注意的是，不同的安全防护中只有防电墙是标配的，“出水断电”和“PS安全系统”一般出现在1500元以上的中高端机型上。 其实电热水器的选购一点也不难，别听商家“忽悠”了，我们只要关注几个方面就够，其它不用考虑太多，今天我给大家总结一下。 1、容量的选择 储水式电热水器有不同的规格，具体表现为容量大小，容量越大，代表电热水器能够储存的水量越多，反之则越少。我们在选购电热水器时，容量的选择虽然是基础，但却很重要，容量选小了，热水不够用，容量选大了，我们就要花很长的时间“等热水”，浪费电，卫生间可能还放不下。 热水器是家庭电器里的“标配”，电热水器作为家用热水器中的一种，一直是我们家庭的主流选择。在市面上的电热水器品牌和款式众多，今天我们就来聊聊美的电热水器。 在正文开始前，先推荐两款性价比高且京东销量火爆的美的电热水器，方便熟悉美的电热水器的朋友直接选购 美的从1999年开始生产热水器，凭借着品牌强大的综合实力，美的电热水器在市场上表现稳定，占有率常年位居三甲之列，与海尔竞争互有胜负。搪瓷-金属复合型内胆如今已是电热水器的主流，无论各大厂商如何宣传，本质上都是在这种复合结构上进行改良，美的全系产品标配其专利搪瓷内胆，由外至里分别是低碳钢板层、微粉搪瓷层和高温煅烧蓝涂层，兼顾抗压和防腐性能，使用寿命也很持久，美的对内胆提供8年包修服务，与A.O.史密斯的承诺质保期相同。\n",
      "1. 产品描述：美的终极舒适系列电热水器，配备多重安全防护，包括防电墙、出水断电、干烧漏电自动断电及PS安全系统，从源头上切断触电可能。全系标配专利搪瓷内胆，兼具抗压与防腐性能，提供8年包修服务，确保使用寿命。\n",
      "\n",
      "2. 产品卖点：美的终极舒适系列电热水器以其卓越的安全性能和持久耐用的内胆设计，为用户提供放心舒适的热水体验。\n",
      "\n",
      "3. 最佳营销卖点：多重安全防护设计是美的终极舒适系列电热水器的核心卖点，因为它直接回应了消费者对安全性的首要关注，从源头上切断触电可能，让用户安心享受热水。\n",
      "\n",
      "4. 目标受众：注重家庭安全、追求高品质热水体验的家庭用户，特别是有老人和儿童的家庭，以及对电热水器安全性有较高要求的消费者。\n",
      "round:  2\n",
      "there are  14  chunks\n",
      "there are  1024  elements in ctxt_embed\n",
      "there are  13  elements in search_embed\n",
      "the context we are giving is:  参考价:13998.0 XQS100-BZ568H 参考价:3699.0 抱歉，没有找到相关产品 看完就心动，解锁海尔神秘黑科技 新版传奇，开局3分钟爆，装备随便爆！ 接下来播放 自动连播 海尔白色376洗烘套装，力度真的大，错过挺可惜的#海尔洗烘套装#海尔376白色套装 小米VS领普-电池人在传感器 护眼时刻1 2024年618洗烘套装推荐！海尔小天鹅卡萨帝博世松下东芝lg怎么样？蓝氧2.0小乌梅白月光玉兔白珍珠水魔方评测吗？洗烘一体机有高性价比选购攻略哪个品牌好怎么选 618洗烘套装推荐2024年！蓝氧小乌梅白月光玉兔白珍珠水魔方评测吗？洗烘一体机洗衣机有高性价比选购攻略哪个品牌好怎么选海尔小天鹅卡萨帝博世松下东芝lg怎么样？ 【618洗烘套装排行榜】榜单里洗烘套装真的实至名归吗，海尔和小天鹅表现到底怎么样 【618-洗衣机篇】2024年618洗衣机最全保姆级选购攻略！全篇23分钟，包含滚筒（洗烘套装、洗烘一体)、波轮全类型详细分析！防踩坑级！看完你就懂！ 具身智能基础技术路线 参考价:1299.0 EB100B37Mate5 参考价:2499.0 G100518BD12S 参考价:3499.0 XQS100-BE568 参考价:3999.0 HGS100-356 参考价:6999.0 XQB100-Z606 参考价:1399.0 EB100Z33Mate1 参考价:1249.0 XQBM30-R377 参考价:1299.0 XQGF140-HB1268U1 参考价:9999.0 HGS100-519 参考价:6999.0 EG80MATE33S 参考价:2599.0 EGM30707 参考价:1999.0 HQ1-TB278C 参考价:2999.0 MBM33-R500 参考价:1999.0 HGS100-F26PLUS 参考价:8999.0 HQ1-TB278B 参考价:2999.0 HQ1-TB278W 参考价:2999.0 EMS100B37Mate6\n",
      "1. 产品描述：Haier HB18FGSAAA，海尔旗下的一款高端产品，以其出色的性能和创新的设计，为用户带来全新的使用体验。\n",
      "\n",
      "2. 产品卖点：Haier HB18FGSAAA作为海尔的高端产品，融合了卓越性能与创新设计，旨在为用户提供前所未有的便捷与舒适体验。\n",
      "\n",
      "3. 最佳营销卖点：其创新设计是Haier HB18FGSAAA的最大亮点，因为消费者对于新颖、与众不同的产品设计总是充满好奇和兴趣，这将有助于产品在市场上脱颖而出。\n",
      "\n",
      "4. 目标受众：追求高品质生活、注重产品设计与性能的中高端消费者，以及对海尔品牌有深厚信任感的用户群体。\n",
      "round:  3\n",
      "there are  24  chunks\n",
      "there are  1024  elements in ctxt_embed\n",
      "there are  23  elements in search_embed\n",
      "the context we are giving is:  京东查看价格 联想Yoga 9i笔记本电脑重量为1.4公斤，屏占比达到78.1%，整机尺寸为319.4 x 216.4 x 14.6-15.7 毫米 (12.57 x 8.52 x 0.57-0.62 inches)，屏幕分辨率为1920 x 1080，搭载了Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡，综合得分为57分。 应用程序性能 在流行的 3D 游戏中的表现 视角、色彩准确度、亮度 轻度和平均使用情况下的电池寿命 端口、网络摄像头和其他接口 设计、材料、耐用性和可用性 综合各个性能参数评分 以下是笔记本电脑决策读者对联想Yoga 9i的六个最受欢迎的比较 京东查看价格 推荐理由： 京东查看价格 推荐理由： 笔记本搭配Intel Core i5 11260H处理器和 GeForce GTX 1650 Mobile 4GB显卡,1920 x 1080 (60Hz)屏幕显示效果不错，可应对大部分应用程序； 京东查看价格 推荐理由： 笔记本搭配Intel Core i5 1135G7处理器和 Intel Iris Xe Graphics G7 (80EU)显卡,2560 x 1600屏幕显示效果不错，可应对大部分应用程序； 京东查看价格 推荐理由： 笔记本搭配Intel Core i5 1135G7处理器和 Intel Iris Xe Graphics G7 (80EU)显卡,1920 x 1080屏幕显示效果不错，可应对大部分应用程序； 京东查看价格 推荐理由： 笔记本搭配AMD Ryzen 5 5600U处理器和 Radeon RX Vega 7显卡,1920 x 產品以實物為準以上有關產品之配置只供參考，並只代表產品可配備之最高規格，有關配置或其配件有可能因應本地條例、供應限制等問題而不適用於香港市場。請您下單前參考具體型號的詳細配置描述。保固服務：產品保固服務將視個別國家地區而定，某些服務及/或零件並非於所有國家/地區均可取得。針對第三方提供的產品或服務，Lenovo 概不負責或擔起保養之責。Lenovo 有限保養僅適用於貴客戶基於自用而非轉售用途所購買之 Lenovo 硬件產品。商標： Lenovo、ThinkPad、ThinkCentre 及 Lenovo 標誌均為 Lenovo 的商標。Microsoft、Windows、Windows NT 及 Windows 標誌是 Microsoft Corporation 的商標。Ultrabook、Celeron、Celeron Inside、Core Inside、Intel、Intel\n",
      "1. 产品描述：Lenovo Yoga 9i Gen 8笔记本电脑，重量仅为1.4公斤，屏占比高达78.1%，整机尺寸紧凑。它配备了1920 x 1080的屏幕分辨率，搭载了Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡，性能出色，足以应对大部分应用程序。\n",
      "\n",
      "2. 产品卖点：Lenovo Yoga 9i Gen 8笔记本电脑以其1.4公斤的轻便设计、78.1%的高屏占比、1920 x 1080的高清屏幕分辨率，以及搭载的Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡带来的强大性能，为用户提供了既美观又实用的全新体验。\n",
      "\n",
      "3. 最佳营销卖点：Lenovo Yoga 9i Gen 8笔记本电脑的强大性能，搭载Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡，可以流畅应对大部分应用程序，满足用户无论是工作还是娱乐的多样化需求。\n",
      "\n",
      "4. 目标受众：这款产品适合追求高性能与便携性的商务人士、学生以及日常使用笔记本电脑进行工作或娱乐的用户。其轻薄的设计、强大的处理器和显卡配置，以及高清的屏幕分辨率，都能满足这部分用户群体的核心需求。\n",
      "round:  4\n",
      "there are  17  chunks\n",
      "there are  1024  elements in ctxt_embed\n",
      "there are  16  elements in search_embed\n",
      "the context we are giving is:  小米手环8作为一款功能全面的智能手环，不仅具备了丰富的健康监测功能，还拥有时尚的设计和长久的续航能力。通过本文的介绍，相信您已经掌握了小米手环8的开机方法、功能特色以及日常保养技巧。希望这款手环能够为您的健康生活提供有力的支持。如果遇到任何问题，不妨查阅用户手册、联系小米客服或寻求专业维修人员的帮助，让您的手环焕发新的生机。 特别声明：以上内容(如有图片或视频亦包括在内)为自媒体平台“网易号”用户上传并发布，本平台仅提供信息存储服务。 Notice: The content above (including the pictures and videos if any) is uploaded and posted by a user of NetEase Hao, which is a social media platform and only provides information 小米手环8作为一款功能全面的智能手环，不仅具备了丰富的健康监测功能，还拥有时尚的设计和长久的续航能力。通过本文的介绍，相信您已经掌握了小米手环8的开机方法、功能特色以及日常保养技巧。希望这款手环能够为您的健康生活提供有力的支持。如果遇到任何问题，不妨查阅用户手册、联系小米客服或寻求专业维修人员的帮助，让您的手环焕发新的生机。 亮度，采用跑道形设计，拥有无极自动亮度调节；采用快拆结构，带来“淡金”“亮黑”两款中框配色，还支持全新的项链形态。 京东小米 手环 8 标准版 169.16 元直达链接 京东小米 手环 8NFC 版 218.69 元直达链接 京东 618 无门槛红包至高 24618 元：点此抽今日红包 淘宝 618 无门槛红包至高 24888 元：点此抽今日红包 广告声明：文内含有的对外跳转链接（包括不限于超链接、二维码、口令等形式），用于传递更多信息，节省甄选时间，结果仅供参考，IT之家所有文章均包含本声明。 特别声明：以上内容(如有图片或视频亦包括在内)为自媒体平台“网易号”用户上传并发布，本平台仅提供信息存储服务。 Notice: The content above (including the pictures and videos if any) is uploaded and posted\n",
      "1. 产品描述：小米手环8是一款功能全面的智能手环，具备丰富的健康监测功能，同时拥有时尚设计和长久续航能力。它采用跑道形设计，支持无极自动亮度调节，拥有快拆结构及“淡金”与“亮黑”两款中框配色，还支持全新的项链形态。\n",
      "\n",
      "2. 产品卖点：小米手环8集时尚设计与全面健康监测于一身，提供长久的续航能力，让用户随时随地监测健康状况，同时其独特的跑道形设计和快拆结构，以及“淡金”与“亮黑”的配色选择，满足了用户对智能穿戴设备的个性化需求。\n",
      "\n",
      "3. 最佳营销卖点：小米手环8的丰富健康监测功能是其最大亮点，因为现代消费者越来越注重个人健康管理，这款手环能提供全面的健康数据，帮助用户更好地了解自己的身体状况，从而做出合理的生活和运动调整。\n",
      "\n",
      "4. 目标受众：注重健康管理的年轻人群，包括学生、白领、运动爱好者等，他们追求时尚与科技的结合，希望通过智能设备来监测和改善自己的健康状况。\n",
      "round:  5\n",
      "there are  10  chunks\n",
      "there are  1024  elements in ctxt_embed\n",
      "there are  9  elements in search_embed\n",
      "the context we are giving is:  至于这双安踏KT7的具体配置信息，相信就不用小编过于介绍，球鞋的最大亮点莫过于中底部分所采用的氮科技。这种全新的中底材质的能量回弹率高达82.6%，稳稳地达到了国产顶尖的水平，氮科技的出现，也大大改变了安踏中底科技过于孱弱的困境。 最后要说一下这个安踏KT7十周年限定套装的鞋盒部分，在这个鞋盒的外部，金色的表面印有一个大大的汤普森的人像，当然也是不苟言笑的克莱•汤普森。 虽说，这套安踏KT7十周年限定套装也是采用限量发售的形式，但是如果只是偶尔对特殊事件推出的专属配色采用限量发售的形式，还是能够理解的。 三款配色现在均已在安踏官方网店上架发售，售价 ￥999 元，感兴趣的朋友不妨留意。 安踏 KT7淘口令（复制以下整段）：8.0￥2TZTXIycnxd￥ https://m.tb.cn/h.f36gVag kt7 安踏篮球鞋男专业实战碳板高帮球鞋汤普森2021秋季新款运动鞋【立即下单】 「部分图片来源于网络，如牵涉版权 请联系 feedback@flightclub.cn 更正」 特别声明：以上内容(如有图片或视频亦包括在内)为自媒体平台“网易号”用户上传并发布，本平台仅提供信息存储服务。 Notice: The content above (including the pictures and videos if any) is uploaded and posted by a user of NetEase Hao, which is a social media platform 安踏KT7十周年限定套装正式发布！致敬汤普森十年传奇职业生涯的专属配色 在今天勇士对战纽约尼克斯的比赛中，史蒂芬•库里正式超越雷阿伦，成为了NBA历史三分王。在库里享受外界欢呼祝福的同时，他的老队友、“水花兄弟”的另一个成员克莱•汤普森，还在默默准备着接连两次重伤过后的复出。近日，安踏也为养伤之中的汤普森带来了一份特殊的礼物——全新安踏KT7十周年限定套装，蓦然发现，这位顶级射手原来已经是一个十年的老将了。 此次推出的这个安踏KT7十周年限定套装，除了包含有一双特殊配色的安踏KT7篮球鞋之外，还有一个特殊设计的球鞋盒、一件球衣和一本画册。当然，所有的产品都是以克莱•汤普森十年的职业生涯为设计灵感。\n",
      "1. 产品描述：安踏KT7篮球鞋，中底采用氮科技，能量回弹率高达82.6%，达到国产顶尖水平。十周年限定套装包含特殊配色篮球鞋、特殊设计球鞋盒、球衣和画册，以克莱•汤普森十年职业生涯为设计灵感。\n",
      "\n",
      "2. 产品卖点：安踏KT7篮球鞋搭载顶尖的氮科技中底，提供卓越的回弹性能，同时十周年限定套装极具收藏价值，完美融合实战性能与纪念意义。\n",
      "\n",
      "3. 最佳营销卖点：顶尖的氮科技中底，能量回弹率高达82.6%，为球员带来出色的运动表现。这一卖点最能吸引消费者，因为它直接关联到产品的核心功能——提升运动性能，满足篮球爱好者对专业装备的高要求。\n",
      "\n",
      "4. 目标受众：篮球爱好者，特别是追求专业装备、注重实战性能的球员，以及喜欢收藏限量版运动产品的消费者。\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2dc3d thead th {\n",
       "  background-color: lightslategrey;\n",
       "  color: white;\n",
       "  border: 2px solid darkslategray !important;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_2dc3d_row0_col0, #T_2dc3d_row0_col1, #T_2dc3d_row0_col2, #T_2dc3d_row0_col3, #T_2dc3d_row1_col0, #T_2dc3d_row1_col1, #T_2dc3d_row1_col2, #T_2dc3d_row1_col3, #T_2dc3d_row2_col0, #T_2dc3d_row2_col1, #T_2dc3d_row2_col2, #T_2dc3d_row2_col3, #T_2dc3d_row3_col0, #T_2dc3d_row3_col1, #T_2dc3d_row3_col2, #T_2dc3d_row3_col3, #T_2dc3d_row4_col0, #T_2dc3d_row4_col1, #T_2dc3d_row4_col2, #T_2dc3d_row4_col3 {\n",
       "  background-color: aliceblue;\n",
       "  color: black;\n",
       "  text-align: center;\n",
       "  border: 2px solid lightsteelblue !important;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2dc3d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2dc3d_level0_col0\" class=\"col_heading level0 col0\" >产品描述</th>\n",
       "      <th id=\"T_2dc3d_level0_col1\" class=\"col_heading level0 col1\" >产品卖点</th>\n",
       "      <th id=\"T_2dc3d_level0_col2\" class=\"col_heading level0 col2\" >最佳营销卖点</th>\n",
       "      <th id=\"T_2dc3d_level0_col3\" class=\"col_heading level0 col3\" >目标受众</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2dc3d_row0_col0\" class=\"data row0 col0\" >美的终极舒适系列电热水器，配备多重安全防护，包括防电墙、出水断电、干烧漏电自动断电及PS安全系统，从源头上切断触电可能。全系标配专利搪瓷内胆，兼具抗压与防腐性能，提供8年包修服务，确保使用寿命。</td>\n",
       "      <td id=\"T_2dc3d_row0_col1\" class=\"data row0 col1\" >美的终极舒适系列电热水器以其卓越的安全性能和持久耐用的内胆设计，为用户提供放心舒适的热水体验。</td>\n",
       "      <td id=\"T_2dc3d_row0_col2\" class=\"data row0 col2\" >多重安全防护设计是美的终极舒适系列电热水器的核心卖点，因为它直接回应了消费者对安全性的首要关注，从源头上切断触电可能，让用户安心享受热水。</td>\n",
       "      <td id=\"T_2dc3d_row0_col3\" class=\"data row0 col3\" >注重家庭安全、追求高品质热水体验的家庭用户，特别是有老人和儿童的家庭，以及对电热水器安全性有较高要求的消费者。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2dc3d_row1_col0\" class=\"data row1 col0\" >Haier HB18FGSAAA，海尔旗下的一款高端产品，以其出色的性能和创新的设计，为用户带来全新的使用体验。</td>\n",
       "      <td id=\"T_2dc3d_row1_col1\" class=\"data row1 col1\" >Haier HB18FGSAAA作为海尔的高端产品，融合了卓越性能与创新设计，旨在为用户提供前所未有的便捷与舒适体验。</td>\n",
       "      <td id=\"T_2dc3d_row1_col2\" class=\"data row1 col2\" >其创新设计是Haier HB18FGSAAA的最大亮点，因为消费者对于新颖、与众不同的产品设计总是充满好奇和兴趣，这将有助于产品在市场上脱颖而出。</td>\n",
       "      <td id=\"T_2dc3d_row1_col3\" class=\"data row1 col3\" >追求高品质生活、注重产品设计与性能的中高端消费者，以及对海尔品牌有深厚信任感的用户群体。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2dc3d_row2_col0\" class=\"data row2 col0\" >Lenovo Yoga 9i Gen 8笔记本电脑，重量仅为1.4公斤，屏占比高达78.1%，整机尺寸紧凑。它配备了1920 x 1080的屏幕分辨率，搭载了Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡，性能出色，足以应对大部分应用程序。</td>\n",
       "      <td id=\"T_2dc3d_row2_col1\" class=\"data row2 col1\" >Lenovo Yoga 9i Gen 8笔记本电脑以其1.4公斤的轻便设计、78.1%的高屏占比、1920 x 1080的高清屏幕分辨率，以及搭载的Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡带来的强大性能，为用户提供了既美观又实用的全新体验。</td>\n",
       "      <td id=\"T_2dc3d_row2_col2\" class=\"data row2 col2\" >Lenovo Yoga 9i Gen 8笔记本电脑的强大性能，搭载Intel Core i5 1135G7处理器与Intel Iris Xe Graphics G7 (80EU)显卡，可以流畅应对大部分应用程序，满足用户无论是工作还是娱乐的多样化需求。</td>\n",
       "      <td id=\"T_2dc3d_row2_col3\" class=\"data row2 col3\" >这款产品适合追求高性能与便携性的商务人士、学生以及日常使用笔记本电脑进行工作或娱乐的用户。其轻薄的设计、强大的处理器和显卡配置，以及高清的屏幕分辨率，都能满足这部分用户群体的核心需求。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2dc3d_row3_col0\" class=\"data row3 col0\" >小米手环8是一款功能全面的智能手环，具备丰富的健康监测功能，同时拥有时尚设计和长久续航能力。它采用跑道形设计，支持无极自动亮度调节，拥有快拆结构及“淡金”与“亮黑”两款中框配色，还支持全新的项链形态。</td>\n",
       "      <td id=\"T_2dc3d_row3_col1\" class=\"data row3 col1\" >小米手环8集时尚设计与全面健康监测于一身，提供长久的续航能力，让用户随时随地监测健康状况，同时其独特的跑道形设计和快拆结构，以及“淡金”与“亮黑”的配色选择，满足了用户对智能穿戴设备的个性化需求。</td>\n",
       "      <td id=\"T_2dc3d_row3_col2\" class=\"data row3 col2\" >小米手环8的丰富健康监测功能是其最大亮点，因为现代消费者越来越注重个人健康管理，这款手环能提供全面的健康数据，帮助用户更好地了解自己的身体状况，从而做出合理的生活和运动调整。</td>\n",
       "      <td id=\"T_2dc3d_row3_col3\" class=\"data row3 col3\" >注重健康管理的年轻人群，包括学生、白领、运动爱好者等，他们追求时尚与科技的结合，希望通过智能设备来监测和改善自己的健康状况。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2dc3d_row4_col0\" class=\"data row4 col0\" >安踏KT7篮球鞋，中底采用氮科技，能量回弹率高达82.6%，达到国产顶尖水平。十周年限定套装包含特殊配色篮球鞋、特殊设计球鞋盒、球衣和画册，以克莱•汤普森十年职业生涯为设计灵感。</td>\n",
       "      <td id=\"T_2dc3d_row4_col1\" class=\"data row4 col1\" >安踏KT7篮球鞋搭载顶尖的氮科技中底，提供卓越的回弹性能，同时十周年限定套装极具收藏价值，完美融合实战性能与纪念意义。</td>\n",
       "      <td id=\"T_2dc3d_row4_col2\" class=\"data row4 col2\" >顶尖的氮科技中底，能量回弹率高达82.6%，为球员带来出色的运动表现。这一卖点最能吸引消费者，因为它直接关联到产品的核心功能——提升运动性能，满足篮球爱好者对专业装备的高要求。</td>\n",
       "      <td id=\"T_2dc3d_row4_col3\" class=\"data row4 col3\" >篮球爱好者，特别是追求专业装备、注重实战性能的球员，以及喜欢收藏限量版运动产品的消费者。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x176bce370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate # for creating the template we feed to llm\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain.embeddings import QianfanEmbeddingsEndpoint\n",
    "# ^ for getting the actual GPT llm and also the embeddor\n",
    "from langchain_core.output_parsers import StrOutputParser # for converting llm output to something Python understands\n",
    "import pandas as pd # for making dfs\n",
    "from IPython.display import display # for displaying the df with styling\n",
    "import numpy as np # for doing dot product\n",
    "import requests # for making HTTP request in Python to handle headers, cookies, and authentication\n",
    "from bs4 import BeautifulSoup # for parsing HTML and XML docs so we can get j the urls / body text directly from a webpage\n",
    "import re # for using regex funcs like sub and shit\n",
    "\n",
    "# function to split text since the max length keeps being exceeded\n",
    "def split_text(text):\n",
    "    words = text.split() # splits the input string into a list of individual words\n",
    "    chunks = [] # stores final list of chunks\n",
    "    current_chunk = [] # temp list for each chunk\n",
    "\n",
    "    for word in words: # for each word\n",
    "        if len(\" \".join(current_chunk + [word])) <= 400 and word: # if adding this word doesn't exceed 400 words\n",
    "            current_chunk.append(word) # then it is added\n",
    "        elif current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk)) # else the current chunk is added to the chunks list as a single string\n",
    "            current_chunk = [word] # then current_chunk is refreshed into a new chunk\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk)) # then at the end if there's a current chunk left then that's added to the list\n",
    "\n",
    "    return chunks # returns a list of chunks of max length 400\n",
    "\n",
    "# does web scraping and text searching to search Baidu -> get search urls -> fetch content from urls -> process text\n",
    "def baidu_search(query): # query being the context we got\n",
    "    # defines url for baidu search\n",
    "    url = \"https://www.baidu.com/s\" # baidu (DUH)\n",
    "    \n",
    "    search_query = {'wd': query} # wd stands for word/query which is what we're searching (the context we're taking in)\n",
    "    \n",
    "    headers = { # headers r necessary bc when we as humans make searches we hv these; we need this to mimic a regular web browser's request\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    } # the User-Agent is a commonly used string for web scraping to avoid detection and blocking by webs\n",
    "    \n",
    "    # sends the get request to Baidu w our search params and header to do the search for relevant webpages\n",
    "    response = requests.get(url, params=search_query, headers=headers)\n",
    "    \n",
    "    # we need to initialize a Beautiful Soup object to actually parse the HTML so we can just get the urls\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # making a list to store urls of search results\n",
    "    results = []\n",
    "    # so a webpage will be separated in a bunch of divs as you know, and each div has a class that its associated w\n",
    "    # so when we do soup.find_all('div', class_='result'), we r using the soup object to search across all 'div's for the result class\n",
    "    # and then we r doing a for each loop of all the result divs and finding the link portion of it\n",
    "    for item in soup.find_all('div', class_='result'):\n",
    "        link = item.find('a', href=True) # 'a' is a link notation\n",
    "        if link:\n",
    "            results.append(link['href']) # and if it's a link then we add it into the list w the 'href' attribute which is a url\n",
    "\n",
    "    # now we are making another list based on our results list that takes all the urls there and calls get_page on it to get the acc page\n",
    "    docs = get_page(results) # so this stores a bunch of pages\n",
    "\n",
    "    # making another list to store the acc content of the pages in\n",
    "    content = []\n",
    "    for doc in docs: # for each doc in the docs list\n",
    "        page_text = re.sub(\"\\n\\n+\", \"\\n\", doc) # this regex part is p cool, sub() obviously substitutes something w another thing\n",
    "        # and in this case we r subbing all the \\n\\n+ w j one \\n which means that anything more than 1 newline will be replaced w a newline\n",
    "        # so we can just get all the text in a braindead way like this\n",
    "        if page_text and page_text != \"问题反馈\": # checks to see if empty string or bad text\n",
    "            # ^ note that in Python, an empty string of \"\" returns False\n",
    "            # page_text = cutoff(page_text)\n",
    "            content.append(page_text) # and we r adding it to the list\n",
    "        \n",
    "    # i = 0\n",
    "    # for ctnt in content:\n",
    "    #     i += 1\n",
    "    #     print(\"entry \", i,\": \",ctnt)\n",
    "\n",
    "    return content # and now we r just returning a list of all the text from relevant pages\n",
    "\n",
    "# this is the function that we called in baidu_search to acc get the webpages from the urls\n",
    "def get_page(urls):\n",
    "    \n",
    "    docs = [] # we r making to store the page contents\n",
    "    # similar process w headers as above\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    # a for each loop of all the urls\n",
    "    for url in urls:\n",
    "        \n",
    "        response = requests.get(url, headers=headers) # this time we r j popping into all the pages\n",
    "        \n",
    "        if response.status_code == 200: # status code 200 means that it was successful so if we were let in, then we call beautiful soup\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser') # we initiate the soup object again\n",
    "            # ^ we get the content from the response (the response being the page that we popped into)\n",
    "            # ^ then we specify we wanna use 'html.parser' to get the info\n",
    "            paragraphs = soup.find_all('p') # 'p' = praragraph so now we r making a list of all the paragraphs from the parsed html\n",
    "            # ^ the issue is what if there are text content thats important thats not marked as 'p' or what if 'p' isn't right?\n",
    "            page_text = \"\\n\".join([p.get_text() for p in paragraphs]) # and we extract all the text from the paragraphs & join them\n",
    "            chunks = split_text(page_text) # so that it doesn't keep causing errors\n",
    "            docs.extend(chunks) # and now we add the text into our list of page content\n",
    "    # so finally we can return a list w all the page contents of j all the text on the page\n",
    "    return docs\n",
    "\n",
    "# this is just a function to cut off excess words cuz there's a max that can be embedded\n",
    "# def cutoff(text):\n",
    "#     words = text.split() # this splits all the text into a list of individual word strings\n",
    "#     truncated = \" \".join(words[:742]) # and now we r just joining the words tgt (2000 is max)\n",
    "#     return truncated\n",
    "\n",
    "# key\n",
    "qianfan_ak = \"DAEEqjuvglLTgQMCXqRvqfUj\"\n",
    "qianfan_sk = \"s0AJ849GNB6440lwLWDvGuNEJNrgrbQ3\"\n",
    "\n",
    "# models\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-4.0-8K\", streaming=True, qianfan_ak=qianfan_ak, qianfan_sk=qianfan_sk, penalty_score=1)\n",
    "embed = QianfanEmbeddingsEndpoint(model=\"bge_large_zh\", endpoint=\"bge_large_zh\", qianfan_ak=qianfan_ak, qianfan_sk=qianfan_sk)\n",
    "\n",
    "# does the rag search and returns a list (of strings) with all the info from the first few pages of web links (each link's info is concatenated tgt)\n",
    "def rag_search(query):\n",
    "    return baidu_search(query) # rn we hv them as diff functions in case baidu doesn't work out\n",
    "\n",
    "def df_mk(ar1, ar2, ar3, ar4):\n",
    "    df = pd.DataFrame({ # this is the syntax for making a df which is basically a table in pandas\n",
    "        \"产品描述\": ar1, # the quotes has the title of the column\n",
    "        \"产品卖点\": ar2, # u can either make an array like [val, val] urself\n",
    "        \"最佳营销卖点\": ar3, # or u can use an array that u alr made\n",
    "        \"目标受众\": ar4 # and put it into the df like that\n",
    "    })\n",
    "        \n",
    "    return df\n",
    "\n",
    "def parse_response(llm_output): # this parses the output param that is generated by the llm to find the info we need for the df\n",
    "        \n",
    "    # split the output into lines\n",
    "    lines = llm_output.split('\\n') # split function is a python func that turns a string into a list\n",
    "    # ^ where each newline from the og where the items r separated\n",
    "    \n",
    "    # initialize placeholders\n",
    "    product_description = 'missing description' # this is for debugging in case we find something isn't generated properly\n",
    "    selling_points = 'missing description' # then we know that whatever has \"missing description\" didn't have that part\n",
    "    best_marketing_point = 'missing description'\n",
    "    target_audience = 'missing description'\n",
    "        \n",
    "    # iterate over lines and find the relevant sections\n",
    "    for line in lines: # for each loop that searches each line in the output for the content we need\n",
    "        if line.startswith(\"1. 产品描述：\"): # so if the line starts with [this] then we store this line into the corresponding var\n",
    "            product_description = line[8:].strip() # but we strip the title for cleanliness\n",
    "        elif line.startswith(\"2. 产品卖点：\"):\n",
    "            selling_points = line[8:].strip()\n",
    "        elif line.startswith(\"3. 最佳营销卖点：\"):\n",
    "            best_marketing_point = line[11:].strip()\n",
    "        elif line.startswith(\"4. 目标受众：\"):\n",
    "            target_audience = line[8:].strip()\n",
    "                \n",
    "    return product_description, selling_points, best_marketing_point, target_audience # and we just return the variables\n",
    "\n",
    "\n",
    "def call_marketinGPT():\n",
    "\n",
    "    file_path = \"products.txt\" # this is the file u wanna open\n",
    "    # if it was in a diff path, then u would hv to do ../folder/folder/file.txt instead\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file: # 'r' means read (DUH), utf-8 encoding is standard\n",
    "        prod_descr = file.readlines() # \"with\" makes sure it's closed at the end\n",
    "    # \"as file\" basically sets what's opened into the variable \"file\"\n",
    "    # prod_descr is a list type var that stores everything that is read from the file\n",
    "    # readlines reads all the individual lines (broken apart by \\n) into the list\n",
    "    \n",
    "    prod_descr = [desc.strip() for desc in prod_descr] # prod_descr prior to this would be like [\"prod_des1\\n\", \"prod_des2\\n\"]\n",
    "    # desc is each individual line stored in prod_descr, using desc.strip for each desc gets rid of \\n at the end of each one\n",
    "    # now, prod_descr is like [\"prod_des1\", \"prod_des2\"]\n",
    "    \n",
    "    prompt1 = PromptTemplate(\n",
    "        # template is the prompt that ur using to prompt engineer the GPT\n",
    "                \n",
    "        template = \"\"\"输入一个产品名称后，生成一段简短描述，涵盖其主要卖点、特点和优势。\\n\\n\n",
    "\n",
    "        输入格式：\\n\n",
    "        [{prod}]\\n\\n\n",
    "\n",
    "        输出格式：\\n\n",
    "        [简短描述，包括卖点、特点和优势]\\n\"\"\",\n",
    "        \n",
    "        input_variables = [\"prod\"] # here ur telling the gpt that the input variables it uses will be\n",
    "        # used where {prod} is used in the template\n",
    "    )\n",
    "    \n",
    "    prompt2 = PromptTemplate(\n",
    "                        \n",
    "        template=\"\"\"作为一名零售顾问助手，你的任务是帮助用户分析他们的产品描述，\n",
    "        并提供该产品的卖点、最佳营销卖点、目标受众以及针对目标受众的营销策略。\n",
    "        请根据以下格式进行回复，并且仅根据用户提供的信息进行分析和回答：\\n\\n\n",
    "            1. 产品描述：用户提供的产品详细信息。\\n\n",
    "            2. 产品卖点：根据产品描述，提炼出吸引潜在消费者的关键特点。\\n\n",
    "            3. 最佳营销卖点：从产品卖点中选择最具市场潜力的特点，并解释为何这个卖点最有吸引力。\\n\n",
    "            4. 目标受众：根据产品卖点，确定最适合的消费群体。\\n\\n\n",
    "            \n",
    "        以下是一个示例对话：\\n\n",
    "        \n",
    "        用户：我们有一款新型的可折叠电动自行车，重量轻，电池续航长，适合城市通勤。\\n\\n\n",
    "        系统：\\n\n",
    "            1. 产品描述：新型可折叠电动自行车，重量轻，电池续航长，适合城市通勤。\\n\n",
    "            2. 产品卖点：轻便设计、长续航电池、便捷的城市通勤工具。\\n\n",
    "            3. 最佳营销卖点：长续航电池，因为城市通勤用户对续航时间有较高需求，能够减少充电频率。\\n\n",
    "            4. 目标受众：城市白领、大学生、注重环保和便捷出行的用户。\\n\\n\n",
    "            \n",
    "        请提供您的产品描述：\\n\n",
    "        \n",
    "        {prod}\\n\\n\n",
    "\n",
    "        1. 产品描述：用户提供的产品描述\\n\n",
    "        2. 产品卖点：提炼出的产品卖点\\n\n",
    "        3. 最佳营销卖点：选择的最佳营销卖点及其原因\\n\n",
    "        4. 目标受众：确定的目标消费群体\\n\n",
    "        \n",
    "        请注意，产品卖点部分应当是一个完整的句子，不要使用任何形式的项目符号或列表，以免造成文本格式的混乱。\\n\n",
    "\n",
    "        主要使用以下信息来得出答案。即使以下信息提到其他具体产品，也要专注于该产品的优点，不提及其他产品的名称。：\\n\\n\n",
    "        \n",
    "        {context}\"\"\",\n",
    "        \n",
    "        input_variables = [\"prod\", \"context\"] # here ur telling the gpt that the input variables it uses will be\n",
    "    )\n",
    "    \n",
    "    ar1, ar2, ar3, ar4 = [], [], [], [] # here ur declaring the arrays that the df will be made w\n",
    "    \n",
    "    for prod_des in prod_descr: # this is a for-each loop which ensures that each val in the list is used\n",
    "        \n",
    "        marketinGPT = prompt1 | llm | StrOutputParser()\n",
    "        \n",
    "        ctxt = marketinGPT.invoke({\"prod\": prod_des})\n",
    "        \n",
    "        # do RAG search and embed the context and search results\n",
    "        ctxt_embed = embed.embed_query(ctxt) # uses the langchain qianfan embedder\n",
    "        search_results = rag_search(ctxt) # calls the RAG search func to get the list of search results for the context we r looking for\n",
    "        \n",
    "        all_chunks = [] # makes a list to store the chunks\n",
    "        for result in search_results: # for every single result we get\n",
    "            chunks = split_text(result) # we split the result into a list of chunks\n",
    "            all_chunks.extend(chunks) # and adds all the chunks to the list separately\n",
    "            # ^ that's the diff between extend (which adds all the chunks separately) vs append (which would turn it into a list of lists of chunks)\n",
    "        \n",
    "        search_embed = [] # makes a list for the embeddings bc the embedding model has a max num of tokens that is exceeded by big chunks\n",
    "        i1 = 0 # initializes two counters\n",
    "        i2 = 0\n",
    "        while i2 < len(all_chunks) - 1: # while loop for until all chunks r processed\n",
    "            i2 += 1\n",
    "            search_embed.extend(embed.embed_documents(all_chunks[i1:i2])) # then embeds the search results chunk by chunk\n",
    "            i1 += 1\n",
    "        # ^ perhaps not the most efficient so potentially REWORK but effective rn\n",
    "        \n",
    "        # calculate dot product and get closest results\n",
    "        search_embed = np.array(search_embed)\n",
    "        \n",
    "        similarity_scores = np.dot(ctxt_embed, search_embed.T) # this will get all the dot products for our searches X context\n",
    "        filtered_results = [(result, score) for result, score in zip(search_results, similarity_scores) if score > 0.5]\n",
    "        # ^ gets rid of any useless unrelated results\n",
    "        max_ctxt = 3 # sets the max num of ctxt to 3 to not overload the model\n",
    "        if len(filtered_results) < 3: # if there r less than 3 pieces of usable context\n",
    "            max_ctxt = len(filtered_results) # then we use all of them  \n",
    "        top_results = sorted(filtered_results, key=lambda x: x[1], reverse=True)[:max_ctxt] # this sorts the searches for highest matches\n",
    "        # previously used the zip() function, which combines two lists into a list of tuples made up of the results and their scores\n",
    "        # sorted() sorts the function (DUH) based on \"key=lambda x: x[1]\" which means that it sorts on the second element (the scores)\n",
    "        # reverse=True means that it's sorted in descending order rather than ascending so top scores r on the top\n",
    "        # [:4] is the slice notation for getting the first up to :\"x\" index, so this would be the first 4 items\n",
    "        \n",
    "        rag_results = \" \".join([result[0] for result in top_results]) # turns the top 3 results into one string to be fed into prompt\n",
    "                \n",
    "        marketinGPT = prompt2 | llm | StrOutputParser() # this is the setup for the processing pipeline\n",
    "        # prompt refers to the template ur using to prompt engineer -> this is given to llm\n",
    "        # llm then takes the text input and generates a response\n",
    "        # StrOutputParser is an output parser (DUH but also an output parser takes raw output and turns it into a structured format)\n",
    "        # ^ this turns the llm's output into something Python can easily understand\n",
    "        # using the '|' operator is basically the chaining part of the processing pipeline\n",
    "        # ^ this says the output of one component should be used as the input of the next component\n",
    "        # ^ so the prompt's output is the llm's input, the llm's output is the parser's input\n",
    "        \n",
    "        try: # we using a try-except bc who knows if the GPT will output something that is always understandable\n",
    "                        \n",
    "            ans = marketinGPT.invoke({\"prod\": prod_des, \"context\": rag_results}) # marketinGPT (brilliant name) is the name of the pipeline\n",
    "            # so when we call it, we r getting an instance of it\n",
    "            # .invoke(input val) is a method that tells the model to provide a response based on the input val\n",
    "            # \"prod\" is the input variable in the prompt, prod_des is the value in the for-each loop\n",
    "            # this lets prod_des be passed in as the input of the prompt\n",
    "            # ^ same for rag_result\n",
    "            \n",
    "            parsed_response = parse_response(ans) # here we use parse_response to parse the response (DUH)\n",
    "            \n",
    "            ar1.append(parsed_response[0]) # here we r appending (adding) the answer to the arrays\n",
    "            ar2.append(parsed_response[1]) # hopefully everything is right\n",
    "            ar3.append(parsed_response[2]) # but otherwise it will all be missing descriptions\n",
    "            ar4.append(parsed_response[3]) # so this tells us if the GPT failed to generate an expected portion\n",
    "            \n",
    "        except Exception as e: # this is just the exception portion\n",
    "            print(f\"Couldn't process: {prod_des}. Error: {e}\") # we r just saying if we couldn't process any part of the inputs\n",
    "            ar1.append('could not process')\n",
    "            ar2.append('could not process')\n",
    "            ar3.append('could not process')\n",
    "            ar4.append('could not process')\n",
    "\n",
    "    return df_mk(ar1, ar2, ar3, ar4) # finally we make the df w the arrays we built\n",
    "\n",
    "# creating the df\n",
    "df = call_marketinGPT()\n",
    "\n",
    "# styling df\n",
    "styled_df = df.style.set_properties(**{ # so we're just making another df based on the generated df but w styling\n",
    "    'background-color': 'aliceblue', # the syntax for setting stuff is [what u wanna set]: [val]\n",
    "    'color': 'black',\n",
    "    'text-align': 'center',\n",
    "    'border': '2px solid lightsteelblue !important'\n",
    "}).set_table_styles([ # below, the selector means it applies to all the following, being thead, which is the table header section (thead)'s table headers (th)\n",
    "    {'selector': 'thead th', 'props': [('background-color', 'lightslategrey'), ('color', 'white'), ('border', '2px solid darkslategray !important'), ('text-align', 'center')]}\n",
    "]).hide(axis=\"index\") # ^ marked border as !important to make sure it's done bc it kept on NOT appearing??\n",
    "\n",
    "# displaying the styled df\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1e49a thead th {\n",
       "  background-color: lightslategrey;\n",
       "  color: white;\n",
       "  border: 2px solid darkslategray !important;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_1e49a_row0_col0, #T_1e49a_row0_col1, #T_1e49a_row0_col2, #T_1e49a_row0_col3, #T_1e49a_row1_col0, #T_1e49a_row1_col1, #T_1e49a_row1_col2, #T_1e49a_row1_col3, #T_1e49a_row2_col0, #T_1e49a_row2_col1, #T_1e49a_row2_col2, #T_1e49a_row2_col3, #T_1e49a_row3_col0, #T_1e49a_row3_col1, #T_1e49a_row3_col2, #T_1e49a_row3_col3, #T_1e49a_row4_col0, #T_1e49a_row4_col1, #T_1e49a_row4_col2, #T_1e49a_row4_col3 {\n",
       "  background-color: aliceblue;\n",
       "  color: black;\n",
       "  text-align: center;\n",
       "  border: 2px solid lightsteelblue !important;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1e49a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_1e49a_level0_col0\" class=\"col_heading level0 col0\" >产品描述</th>\n",
       "      <th id=\"T_1e49a_level0_col1\" class=\"col_heading level0 col1\" >产品卖点</th>\n",
       "      <th id=\"T_1e49a_level0_col2\" class=\"col_heading level0 col2\" >最佳营销卖点</th>\n",
       "      <th id=\"T_1e49a_level0_col3\" class=\"col_heading level0 col3\" >目标受众</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_1e49a_row0_col0\" class=\"data row0 col0\" >Midea Ultimate Comfort Series - 美的终极舒适系列，致力于为用户提供极致的舒适体验。系列产品包括高性能空调、智能热水器以及多功能空气净化器，均采用先进的节能技术，不仅功能强大而且操作简单，满足现代家庭对高品质生活的追求。</td>\n",
       "      <td id=\"T_1e49a_row0_col1\" class=\"data row0 col1\" >极致舒适体验、高性能空调、智能热水器、多功能空气净化器、先进节能技术、强大功能、简单操作、满足高品质生活追求。</td>\n",
       "      <td id=\"T_1e49a_row0_col2\" class=\"data row0 col2\" >极致舒适体验。这个卖点凸显了产品的核心理念，即为用户提供无与伦比的舒适感。在现代社会，人们对家居生活的舒适度要求越来越高，这一卖点能够直接触及消费者的核心需求，吸引他们购买。</td>\n",
       "      <td id=\"T_1e49a_row0_col3\" class=\"data row0 col3\" >追求高品质生活的中高端消费者，包括注重家居舒适度的家庭用户、对智能家电有较高要求的年轻人群，以及关心节能环保的环保意识较强的消费者。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1e49a_row1_col0\" class=\"data row1 col0\" >Haier HB18FGSAAA - 海尔 HB18FGSAAA，一款高性能的冰箱，采用了先进的冷藏技术，确保食物长时间新鲜。其大容量设计，可轻松存储全家人的食材需求。同时，这款冰箱运行静音，节能省电，为家庭创造宁静且环保的生活环境。简洁时尚的外观设计，能够融入各种家居风格，提升整体家居美感。</td>\n",
       "      <td id=\"T_1e49a_row1_col1\" class=\"data row1 col1\" >先进冷藏技术、大容量存储、静音运行、节能省电、时尚外观设计。</td>\n",
       "      <td id=\"T_1e49a_row1_col2\" class=\"data row1 col2\" >先进冷藏技术，因为保鲜是冰箱最核心的功能，而先进的技术能确保食物长时间新鲜，满足消费者对食品质量和健康的高要求。</td>\n",
       "      <td id=\"T_1e49a_row1_col3\" class=\"data row1 col3\" >追求高品质生活的家庭，注重食品健康和保鲜的消费者，喜欢时尚家居设计的用户。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1e49a_row2_col0\" class=\"data row2 col0\" >Lenovo Yoga 9i Gen 8 - 联想 Yoga 9i 第八代，是一款兼具高性能与多模式转换的笔记本电脑。它搭载最新一代处理器，提供强劲的计算能力，同时其独特的360度翻转设计，让用户可以根据需求轻松切换笔记本、平板、帐篷等多种使用模式。此外，高清触控屏带来出色的视觉体验，适合各种办公与娱乐场景。</td>\n",
       "      <td id=\"T_1e49a_row2_col1\" class=\"data row2 col1\" >高性能处理器、多模式转换设计、高清触控屏、适应多种场景。</td>\n",
       "      <td id=\"T_1e49a_row2_col2\" class=\"data row2 col2\" >多模式转换设计。这一特点使得Lenovo Yoga 9i Gen 8不仅仅是一台传统的笔记本电脑，更能满足用户在不同场合下的多样化需求。无论是正式的办公会议，还是休闲娱乐，都能通过简单的翻转动作找到最舒适的使用方式。</td>\n",
       "      <td id=\"T_1e49a_row2_col3\" class=\"data row2 col3\" >商务人士、创意工作者、对科技产品有较高要求的学生群体，以及希望拥有一台既实用又具备多功能性的笔记本电脑的消费者。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1e49a_row3_col0\" class=\"data row3 col0\" >Xiaomi Mi Band 8 - 小米手环8，是一款功能全面的智能手环。它拥有出色的健康监测功能，包括心率检测、血氧检测、睡眠跟踪等，帮助用户全面了解自己的身体状况。此外，小米手环8还支持多种运动模式，能够精确记录运动数据，助力用户达成健身目标。其时尚的外观设计和长久的电池续航也是产品的亮点，让用户在享受智能科技带来的便利的同时，也能展现自己的个性魅力。</td>\n",
       "      <td id=\"T_1e49a_row3_col1\" class=\"data row3 col1\" >功能全面、健康监测、多种运动模式、时尚外观、长久电池续航。</td>\n",
       "      <td id=\"T_1e49a_row3_col2\" class=\"data row3 col2\" >功能全面，因为小米手环8不仅提供了健康监测功能，还支持多种运动模式，满足了消费者对于智能手环多元化的需求。这种一站式的服务能够吸引更广泛的消费者群体，提升产品的市场竞争力。</td>\n",
       "      <td id=\"T_1e49a_row3_col3\" class=\"data row3 col3\" >注重健康管理的年轻人、经常进行运动的人群、追求时尚科技的消费者。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1e49a_row4_col0\" class=\"data row4 col0\" >Anta KT7 - 安踏 KT7，专业篮球鞋款，采用高科技缓震材料，提供卓越的弹跳支撑。鞋面采用透气材质，确保脚部干爽舒适。抗滑耐磨的鞋底设计，适应各种球场地面，助力球员发挥最佳表现。</td>\n",
       "      <td id=\"T_1e49a_row4_col1\" class=\"data row4 col1\" >专业篮球鞋款、高科技缓震材料、卓越弹跳支撑、透气鞋面、抗滑耐磨鞋底。</td>\n",
       "      <td id=\"T_1e49a_row4_col2\" class=\"data row4 col2\" >卓越弹跳支撑，因为篮球运动员对于鞋子的弹跳性能要求极高，这一卖点直接关联到球员在比赛中的表现，能够满足专业球员对鞋子功能性的核心需求。</td>\n",
       "      <td id=\"T_1e49a_row4_col3\" class=\"data row4 col3\" >专业篮球运动员、篮球爱好者、追求高性能篮球鞋的消费者。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17404a8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate # for creating the template we feed to llm\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain.embeddings import QianfanEmbeddingsEndpoint\n",
    "# ^ for getting the actual GPT llm and also the embeddor\n",
    "from langchain_core.output_parsers import StrOutputParser # for converting llm output to something Python understands\n",
    "import pandas as pd # for making dfs\n",
    "from IPython.display import display # for displaying the df with styling\n",
    "import numpy as np # for doing dot product\n",
    "import requests # for making HTTP request in Python to handle headers, cookies, and authentication\n",
    "from bs4 import BeautifulSoup # for parsing HTML and XML docs so we can get j the urls / body text directly from a webpage\n",
    "import re # for using regex funcs like sub and shit\n",
    "\n",
    "# key\n",
    "qianfan_ak = \"DAEEqjuvglLTgQMCXqRvqfUj\"\n",
    "qianfan_sk = \"s0AJ849GNB6440lwLWDvGuNEJNrgrbQ3\"\n",
    "\n",
    "# models\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-4.0-8K\", streaming=True, qianfan_ak=qianfan_ak, qianfan_sk=qianfan_sk, penalty_score=1)\n",
    "embed = QianfanEmbeddingsEndpoint(model=\"bge_large_zh\", endpoint=\"bge_large_zh\", qianfan_ak=qianfan_ak, qianfan_sk=qianfan_sk)\n",
    "\n",
    "def df_mk(ar1, ar2, ar3, ar4):\n",
    "    df = pd.DataFrame({ # this is the syntax for making a df which is basically a table in pandas\n",
    "        \"产品描述\": ar1, # the quotes has the title of the column\n",
    "        \"产品卖点\": ar2, # u can either make an array like [val, val] urself\n",
    "        \"最佳营销卖点\": ar3, # or u can use an array that u alr made\n",
    "        \"目标受众\": ar4 # and put it into the df like that\n",
    "    })\n",
    "        \n",
    "    return df\n",
    "\n",
    "def parse_response(llm_output): # this parses the output param that is generated by the llm to find the info we need for the df\n",
    "    \n",
    "    # split the output into lines\n",
    "    lines = llm_output.split('\\n') # split function is a python func that turns a string into a list\n",
    "    # ^ where each newline from the og where the items r separated\n",
    "    \n",
    "    # initialize placeholders\n",
    "    product_description = 'missing description' # this is for debugging in case we find something isn't generated properly\n",
    "    selling_points = 'missing description' # then we know that whatever has \"missing description\" didn't have that part\n",
    "    best_marketing_point = 'missing description'\n",
    "    target_audience = 'missing description'\n",
    "    \n",
    "    # iterate over lines and find the relevant sections\n",
    "    for line in lines: # for each loop that searches each line in the output for the content we need\n",
    "        if line.startswith(\"1. **产品描述**：\"): # so if the line starts with [this] then we store this line into the corresponding var\n",
    "            product_description = line[len(\"1. **产品描述**：\"):].strip() # but we strip the title for cleanliness\n",
    "        elif line.startswith(\"2. **产品卖点**：\"):\n",
    "            selling_points = line[len(\"2. **产品卖点**：\"):].strip()\n",
    "        elif line.startswith(\"3. **最佳营销卖点**：\"):\n",
    "            best_marketing_point = line[len(\"3. **最佳营销卖点**：\"):].strip()\n",
    "        elif line.startswith(\"4. **目标受众**：\"):\n",
    "            target_audience = line[len(\"4. **目标受众**：\"):].strip()\n",
    "    \n",
    "    return product_description, selling_points, best_marketing_point, target_audience # and we just return the variables\n",
    "\n",
    "\n",
    "def call_marketinGPT():\n",
    "\n",
    "    file_path = \"products.txt\" # this is the file u wanna open\n",
    "    # if it was in a diff path, then u would hv to do ../folder/folder/file.txt instead\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file: # 'r' means read (DUH), utf-8 encoding is standard\n",
    "        prod_descr = file.readlines() # \"with\" makes sure it's closed at the end\n",
    "    # \"as file\" basically sets what's opened into the variable \"file\"\n",
    "    # prod_descr is a list type var that stores everything that is read from the file\n",
    "    # readlines reads all the individual lines (broken apart by \\n) into the list\n",
    "    \n",
    "    prod_descr = [desc.strip() for desc in prod_descr] # prod_descr prior to this would be like [\"prod_des1\\n\", \"prod_des2\\n\"]\n",
    "    # desc is each individual line stored in prod_descr, using desc.strip for each desc gets rid of \\n at the end of each one\n",
    "    # now, prod_descr is like [\"prod_des1\", \"prod_des2\"]\n",
    "    \n",
    "    prompt2 = PromptTemplate(\n",
    "                        \n",
    "        template=\"\"\"作为一名零售顾问助手，你的任务是帮助用户分析他们的产品描述，\n",
    "        并提供该产品的卖点、最佳营销卖点、目标受众以及针对目标受众的营销策略。\n",
    "        请根据以下格式进行回复，并且仅根据用户提供的信息进行分析和回答：\\n\\n\n",
    "            1. **产品描述**：用户提供的产品详细信息。\\n\n",
    "            2. **产品卖点**：根据产品描述，提炼出吸引潜在消费者的关键特点。\\n\n",
    "            3. **最佳营销卖点**：从产品卖点中选择最具市场潜力的特点，并解释为何这个卖点最有吸引力。\\n\n",
    "            4. **目标受众**：根据产品卖点，确定最适合的消费群体。\\n\\n\n",
    "            \n",
    "        以下是一个示例对话：\\n\n",
    "        \n",
    "        用户：我们有一款新型的可折叠电动自行车，重量轻，电池续航长，适合城市通勤。\\n\\n\n",
    "        系统：\\n\n",
    "            1. **产品描述**：新型可折叠电动自行车，重量轻，电池续航长，适合城市通勤。\\n\n",
    "            2. **产品卖点**：轻便设计、长续航电池、便捷的城市通勤工具。\\n\n",
    "            3. **最佳营销卖点**：长续航电池，因为城市通勤用户对续航时间有较高需求，能够减少充电频率。\\n\n",
    "            4. **目标受众**：城市白领、大学生、注重环保和便捷出行的用户。\\n\\n\n",
    "            \n",
    "        请提供您的产品描述：\\n\n",
    "        \n",
    "        {prod}\\n\\n\n",
    "\n",
    "        1. **产品描述**：用户提供的产品描述\\n\n",
    "        2. **产品卖点**：提炼出的产品卖点\\n\n",
    "        3. **最佳营销卖点**：选择的最佳营销卖点及其原因\\n\n",
    "        4. **目标受众**：确定的目标消费群体\\n\"\"\",\n",
    "        \n",
    "        input_variables = [\"prod\", \"context\"] # here ur telling the gpt that the input variables it uses will be\n",
    "    )\n",
    "    \n",
    "    ar1, ar2, ar3, ar4 = [], [], [], [] # here ur declaring the arrays that the df will be made w\n",
    "\n",
    "    for prod_des in prod_descr: # this is a for-each loop which ensures that each val in the list is used\n",
    "        \n",
    "        marketinGPT = prompt2 | llm | StrOutputParser() # this is the setup for the processing pipeline\n",
    "        # prompt refers to the template ur using to prompt engineer -> this is given to llm\n",
    "        # llm then takes the text input and generates a response\n",
    "        # StrOutputParser is an output parser (DUH but also an output parser takes raw output and turns it into a structured format)\n",
    "        # ^ this turns the llm's output into something Python can easily understand\n",
    "        # using the '|' operator is basically the chaining part of the processing pipeline\n",
    "        # ^ this says the output of one component should be used as the input of the next component\n",
    "        # ^ so the prompt's output is the llm's input, the llm's output is the parser's input\n",
    "        \n",
    "        try: # we using a try-except bc who knows if the GPT will output something that is always understandable\n",
    "                        \n",
    "            ans = marketinGPT.invoke({\"prod\": prod_des}) # marketinGPT (brilliant name) is the name of the pipeline\n",
    "            # so when we call it, we r getting an instance of it\n",
    "            # .invoke(input val) is a method that tells the model to provide a response based on the input val\n",
    "            # \"prod\" is the input variable in the prompt, prod_des is the value in the for-each loop\n",
    "            # this lets prod_des be passed in as the input of the prompt\n",
    "            # ^ same for rag_result\n",
    "            \n",
    "            parsed_response = parse_response(ans) # here we use parse_response to parse the response (DUH)\n",
    "            \n",
    "            ar1.append(parsed_response[0]) # here we r appending (adding) the answer to the arrays\n",
    "            ar2.append(parsed_response[1]) # hopefully everything is right\n",
    "            ar3.append(parsed_response[2]) # but otherwise it will all be missing descriptions\n",
    "            ar4.append(parsed_response[3]) # so this tells us if the GPT failed to generate an expected portion\n",
    "            \n",
    "        except Exception as e: # this is just the exception portion\n",
    "            print(f\"Couldn't process: {prod_des}. Error: {e}\") # we r just saying if we couldn't process any part of the inputs\n",
    "            ar1.append('could not process')\n",
    "            ar2.append('could not process')\n",
    "            ar3.append('could not process')\n",
    "            ar4.append('could not process')\n",
    "\n",
    "    return df_mk(ar1, ar2, ar3, ar4) # finally we make the df w the arrays we built\n",
    "\n",
    "# creating the df\n",
    "df = call_marketinGPT()\n",
    "\n",
    "# styling df\n",
    "styled_df = df.style.set_properties(**{ # so we're just making another df based on the generated df but w styling\n",
    "    'background-color': 'aliceblue', # the syntax for setting stuff is [what u wanna set]: [val]\n",
    "    'color': 'black',\n",
    "    'text-align': 'center',\n",
    "    'border': '2px solid lightsteelblue !important'\n",
    "}).set_table_styles([ # below, the selector means it applies to all the following, being thead, which is the table header section (thead)'s table headers (th)\n",
    "    {'selector': 'thead th', 'props': [('background-color', 'lightslategrey'), ('color', 'white'), ('border', '2px solid darkslategray !important'), ('text-align', 'center')]}\n",
    "]).hide(axis=\"index\") # ^ marked border as !important to make sure it's done bc it kept on NOT appearing??\n",
    "\n",
    "# displaying the styled df\n",
    "display(styled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
